{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jW9bELnJO7rjcqgvr-LwdwRgeP1L3UA4",
      "authorship_tag": "ABX9TyNx268dUAL9EYckaBsHp+9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmandeepSingh285/Lung-Disease-Detection/blob/master/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table width = \"80%\">\n",
        "  <thead>\n",
        "    <th>Charecteristic</th>\n",
        "    <th>Value</th>\n",
        "  </thead>\n",
        "  <tr>\n",
        "    <td> Dataset </td>\n",
        "    <td> Pneumonia </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td> Architecture </td>\n",
        "    <td> AlexNet </td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td> Training </td>\n",
        "    <td> Custom </td>\n",
        "  </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "2LSBMlOIpjan"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkYukkSNpcCX",
        "outputId": "2536e447-d76f-467b-81f3-89636f71b8c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "import glob\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import datetime\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "labels = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Google_Colab/Lung_disease_detection/working_dataset/weights/alexNet.h5\"\n",
        "\n",
        "print(\"Libraries imported\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driveValImages    = os.path.join(os.getcwd(), 'drive/MyDrive/Google_Colab/Lung_disease_detection/working_dataset/val')\n",
        "driveTestImages   = os.path.join(os.getcwd(), 'drive/MyDrive/Google_Colab/Lung_disease_detection/working_dataset/test')\n",
        "driveTrainImages  = os.path.join(os.getcwd(), 'drive/MyDrive/Google_Colab/Lung_disease_detection/working_dataset/train')"
      ],
      "metadata": {
        "id": "fOej0Luqp2YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                   rescale=1/255.0,\n",
        "                   rotation_range=20, \n",
        "                   zoom_range=0.15,\n",
        "                   width_shift_range=0.1,\n",
        "                   height_shift_range=0.1,\n",
        "                   horizontal_flip=True,\n",
        "                   vertical_flip=False,\n",
        "                   )\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255.0\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                   driveTrainImages,\n",
        "                                   target_size=(224, 224),\n",
        "                                   color_mode='rgb',\n",
        "                                   batch_size= 32,\n",
        "                                   class_mode='binary',\n",
        "                                   shuffle = True\n",
        "                                   )\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "                                driveValImages,\n",
        "                                target_size=(224, 224),\n",
        "                                batch_size= 32,\n",
        "                                color_mode='rgb',\n",
        "                                class_mode='binary',\n",
        "                                shuffle = True\n",
        "                                )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "                                driveTestImages,\n",
        "                                target_size=(224, 224),\n",
        "                                batch_size=32,\n",
        "                                shuffle=False,\n",
        "                                class_mode='binary',\n",
        "                                color_mode = 'rgb'\n",
        "                                )\n",
        "\n",
        "print(\"DONE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQayZiLvqAa7",
        "outputId": "56671d85-2b16-48dd-b899-4ad10dd25674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4232 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "DONE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "\n",
        "model.compile(optimizer=optimizer,loss=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'], metrics = ['accuracy', Precision(name = 'precision'), Recall(name = 'recall')] )\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHVOxdQUqGHl",
        "outputId": "22531e87-704e-4319-c0f5-28de76fe1dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 54, 54, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 26, 26, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 26, 26, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 384)       885120    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 12, 12, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 12, 12, 384)      1536      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 12, 12, 256)       884992    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              26218496  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,756,609\n",
            "Trainable params: 46,753,857\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointOne = ReduceLROnPlateau(\n",
        "    monitor = 'val_accuracy',\n",
        "    patience = 2,\n",
        "    verbose = 1,\n",
        "    factor = 0.3,\n",
        "    min_lr = 3e-7\n",
        ")\n",
        "checkpoint_saver = ModelCheckpoint('alexNet.h5', save_best_only=True)\n",
        "checkPointTwo = EarlyStopping(monitor='acc', patience=1)\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%d%m%Y-%H%M\")\n",
        "checkPointThree = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "callbacks_list = [checkpointOne, checkpoint_saver, checkPointTwo, checkPointThree]"
      ],
      "metadata": {
        "id": "-SRSW_vnq04W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=10, validation_data=val_generator, callbacks=callbacks_list) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaRXK1GKq4fi",
        "outputId": "62c91c8f-42a9-45f1-e382-66bbd4110bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.8696 - precision: 0.9160 - recall: 0.9214WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 861s 6s/step - loss: 0.5183 - accuracy: 0.8696 - precision: 0.9160 - recall: 0.9214 - val_loss: 7.9847 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8967 - precision: 0.9345 - recall: 0.9364WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 77s 579ms/step - loss: 0.3345 - accuracy: 0.8967 - precision: 0.9345 - recall: 0.9364 - val_loss: 14.2053 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9227 - precision: 0.9507 - recall: 0.9527\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 76s 574ms/step - loss: 0.2161 - accuracy: 0.9227 - precision: 0.9507 - recall: 0.9527 - val_loss: 19.2833 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9350 - precision: 0.9584 - recall: 0.9604WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 77s 581ms/step - loss: 0.1744 - accuracy: 0.9350 - precision: 0.9584 - recall: 0.9604 - val_loss: 0.4831 - val_accuracy: 0.8750 - val_precision: 0.8089 - val_recall: 0.9820 - lr: 3.0000e-05\n",
            "Epoch 5/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9454 - precision: 0.9652 - recall: 0.9666WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 76s 573ms/step - loss: 0.1400 - accuracy: 0.9454 - precision: 0.9652 - recall: 0.9666 - val_loss: 0.5977 - val_accuracy: 0.8390 - val_precision: 0.7596 - val_recall: 0.9920 - lr: 3.0000e-05\n",
            "Epoch 6/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9513 - precision: 0.9701 - recall: 0.9690WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 77s 579ms/step - loss: 0.1277 - accuracy: 0.9513 - precision: 0.9701 - recall: 0.9690 - val_loss: 0.1566 - val_accuracy: 0.9580 - val_precision: 0.9598 - val_recall: 0.9560 - lr: 3.0000e-05\n",
            "Epoch 7/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9511 - precision: 0.9687 - recall: 0.9701WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 75s 565ms/step - loss: 0.1290 - accuracy: 0.9511 - precision: 0.9687 - recall: 0.9701 - val_loss: 0.1763 - val_accuracy: 0.9340 - val_precision: 0.9411 - val_recall: 0.9260 - lr: 3.0000e-05\n",
            "Epoch 8/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9542 - precision: 0.9705 - recall: 0.9722\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 75s 561ms/step - loss: 0.1149 - accuracy: 0.9542 - precision: 0.9705 - recall: 0.9722 - val_loss: 0.1616 - val_accuracy: 0.9360 - val_precision: 0.9599 - val_recall: 0.9100 - lr: 3.0000e-05\n",
            "Epoch 9/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9591 - precision: 0.9740 - recall: 0.9749WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 77s 577ms/step - loss: 0.1084 - accuracy: 0.9591 - precision: 0.9740 - recall: 0.9749 - val_loss: 0.1226 - val_accuracy: 0.9570 - val_precision: 0.9579 - val_recall: 0.9560 - lr: 9.0000e-06\n",
            "Epoch 10/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9603 - precision: 0.9740 - recall: 0.9764WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
            "133/133 [==============================] - 75s 568ms/step - loss: 0.1026 - accuracy: 0.9603 - precision: 0.9740 - recall: 0.9764 - val_loss: 0.1282 - val_accuracy: 0.9590 - val_precision: 0.9491 - val_recall: 0.9700 - lr: 9.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mv '/content/alexNet.h5' '/content/drive/MyDrive/Google_Colab/Lung_disease_detection/working_dataset/weights/alexNet.h5'"
      ],
      "metadata": {
        "id": "zUlCsq28q_5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "print(\"model loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oDrfroRq7DV",
        "outputId": "268ece45-f03c-4e78-e8fb-1bebfa0d45ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.evaluate(test_generator, return_dict = True)\n",
        "for metric in metrics:\n",
        "  print(f\"{metric} : {metrics[metric]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L31UwsCyrJJ9",
        "outputId": "494598af-5e1d-444c-d9fc-48fd8397daca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 3s 127ms/step - loss: 0.4046 - accuracy: 0.8766 - precision: 0.8455 - recall: 0.9821\n",
            "loss : 0.40461623668670654\n",
            "accuracy : 0.8766025900840759\n",
            "precision : 0.8454746007919312\n",
            "recall : 0.9820512533187866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_generator)\n",
        "predictions = np.round(abs(predictions))\n",
        "classes = test_generator.labels\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwy2CsuOrNBr",
        "outputId": "2aec1088-1d40-4365-c0d2-5fedec74bcc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating confusion matrix\n",
        "\n",
        "xlabels = [\"PREDICTED NORMAL\", \"PREDICTED PNEUMONIA\"]\n",
        "ylabels = [\"ACTUAL NORMAL\", \"ACTUAL PNEUMONIA\"]\n",
        "\n",
        "matrix = confusion_matrix(classes, predictions)\n",
        "sns.heatmap(matrix, annot = True, fmt = \"d\", cmap = \"Blues\", xticklabels = xlabels, yticklabels = ylabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "TvT4LJSWrPzB",
        "outputId": "4ef7ebf2-ae1b-4b7c-92d1-dbb7fab1babd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb2160f7050>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}